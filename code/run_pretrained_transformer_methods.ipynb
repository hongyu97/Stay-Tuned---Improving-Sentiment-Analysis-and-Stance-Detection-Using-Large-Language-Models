{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f864a84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a7cb17f5ab47d6997566587998286c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, EarlyStoppingCallback, TrainingArguments, Trainer, pipeline\n",
    "\n",
    "from scipy.special import softmax\n",
    "from accelerate.utils import release_memory\n",
    "\n",
    "import os, shutil\n",
    "import gc\n",
    "\n",
    "# Set panda options\n",
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "# Set wd and load preprocessed tweets:\n",
    "    \n",
    "os.chdir(\"/home/work/\")\n",
    "\n",
    "# Set up model types:\n",
    "data_names = ['pol', 'user', 'li', 'kawintiranon']\n",
    "subject_names = ['trump', 'biden']\n",
    "train_sets   = ['party', 'nominate', 'handcode'] #['party', 'nominate', 'handcode']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c21491",
   "metadata": {},
   "source": [
    "## Set up datasets and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67077775",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "\n",
    "for data_name in data_names:\n",
    "        df = pd.read_csv(f\"data/processed/{data_name}_tweets_processed.csv\")\n",
    "        datasets[data_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9642e80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab pretrained models using Huggingface. I decided on the specific models\n",
    "# by first searching for 'sentiment' on HF, then sorting by most downloaded.\n",
    "# I knew based on lit review we wanted to incoporate BERT and ROBERTA. I\n",
    "# subsequently chose models based on specific tuning data, from least specific\n",
    "# and smallest (SST) to most problem specific (actual  tweets).\n",
    "\n",
    "# Model using distiliBERT, tuned on Stanford Sentiment Treebank v2\n",
    "\n",
    "# BERT: https://arxiv.org/abs/1810.04805\n",
    "# Distilbert: https://arxiv.org/abs/1910.01108\n",
    "# HF page: https://huggingface.co/assemblyai/distilbert-base-uncased-sst2\n",
    "\n",
    "distilbert_sst = 'assemblyai/distilbert-base-uncased-sst2'\n",
    "\n",
    "# Model using Roberta (a more trained version of BERT), tuned on data obtained\n",
    "# through a systematic review of previous sentiment analysis papers.\n",
    "\n",
    "# Roberta: https://www.sciencedirect.com/science/article/pii/S0167811622000477?via%3Dihub\n",
    "# HF page: https://huggingface.co/siebert/sentiment-roberta-large-english\n",
    "\n",
    "siebert = \"siebert/sentiment-roberta-large-english\"\n",
    "\n",
    "# Model using Roberta, tuned on 124 million tweets and incoporating time-dependency\n",
    "# as part of training.\n",
    "\n",
    "# Ref: https://arxiv.org/abs/2202.03829\n",
    "# HF page: https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest\n",
    "tweet_nlp = 'cardiffnlp/twitter-roberta-base-sentiment-latest'\n",
    "\n",
    "# Ref: http://arxiv.org/abs/2312.17543\n",
    "# HF page: https://huggingface.co/MoritzLaurer/deberta-v3-large-zeroshot-v2.0\n",
    "\n",
    "deberta = 'MoritzLaurer/deberta-v3-large-zeroshot-v2.0'\n",
    "\n",
    "model_names = [distilbert_sst, tweet_nlp, siebert, deberta]\n",
    "model_names_short = ['distilbert', 'tweetnlp', 'siebert', 'deberta']\n",
    "\n",
    "models = dict(zip(model_names_short, model_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0096c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the predicted probabilities into an average scored value.\n",
    "# So, if assigned probabilities are 0.55, 0.45 negative, positive,\n",
    "# then scored value will be -0.05.\n",
    "\n",
    "def average_prob (arr):\n",
    "    \n",
    "    # Set direction of probability to be either negative, zero, or positive, based on shape of preds\n",
    "    if arr.shape[1] == 2:\n",
    "        pred_prob = np.sum([-1, 1]*arr, axis = 1)\n",
    "    elif arr.shape[1] == 3:\n",
    "        pred_prob = np.sum([-1, 0, 1]*arr, axis = 1)\n",
    "    else:\n",
    "        raise ValueError(\"There are more than three predicted classes\")\n",
    "    \n",
    "    return (pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb361742",
   "metadata": {},
   "source": [
    "# Run Pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9c0970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train sentiment model on text data using pretrained models:\n",
    "def zero_model (model_name, subj, dd_name):\n",
    "\n",
    "    print(f\"Estimating scores for {model_name} {dd_name} {subj}\") \n",
    "    \n",
    "    dd = datasets[dd_name].copy()\n",
    "    \n",
    "    # Run model for a given politician\n",
    "    dd = dd[dd.subject == subj]\n",
    "    \n",
    "    # Deberta requires a slightly different input than the other models involving a hypothesis\n",
    "    # and possible classes:\n",
    "    if model_name == 'MoritzLaurer/deberta-v3-large-zeroshot-v2.0':\n",
    "\n",
    "        hypothesis_template = f\"The stance of this text concerning {subj} is \"\n",
    "        hypothesis_template = hypothesis_template + \"{}\"\n",
    "        classes = ['negative', 'positive']\n",
    "        \n",
    "        pipe = pipeline('zero-shot-classification', model = model_name, top_k = None, function_to_apply = 'softmax', device = 0)\n",
    "        scores = pipe(list(dd.text), classes, hypothesis_template = hypothesis_template, multi_label = False)\n",
    "\n",
    "        # The below code looks a little odd but here's the basic idea:\n",
    "        # Hugging face is returning a dictionary that contains either variables for 'sequences, labels, scores',\n",
    "        # or 'labels, scores'. Further, the ordering of 'labels' within the dictionary is not sorted,\n",
    "        # when ideally, it would be ordered alphabetically (negative, neutral, postive).\n",
    "        # So, using list comprehension, extract the labels and scores for each result.  \n",
    "        # Then,  ensure the label pair is ordered, negative -> positive. So,\n",
    "        # using the key parameter within the method sorted, check if the first item is labelled 'positive'. If so,\n",
    "        # the lambda function returns '1', otherwise '0' and sorts the items based on this key from smallest to largest\n",
    "        scores = np.array([[score for label, score in sorted(zip(d['labels'], d['scores']), key = lambda x: x[0] == 'positive')] for d in scores])\n",
    "    \n",
    "    else:\n",
    "\n",
    "        # Use a zero shot classifier to obtain softmax probabilities on each respective class.\n",
    "        # Then, take the mean of these probabilities as the sentiment score.\n",
    "        # device = 0 == use the gpu\n",
    "        pipe = pipeline(model = model_name, top_k = None, function_to_apply = 'softmax', device = 0)\n",
    "        scores = pipe(list(dd.text))\n",
    "\n",
    "        # Using a slightly different strategy for the other models to sort the outputs correctly since the structure\n",
    "        # differs from the deberta return object. Relying on pandas now since this function\n",
    "        # incidentally orders columns alphabetically, and the label names returned from each of the models,\n",
    "        # despite being differently named, just so happen to align with negative, neutral, positive ordering when sorted.\n",
    "        scores = np.array(pd.DataFrame([{d['label']:d['score'] for d in item} for item in scores]))\n",
    "        \n",
    "    scores = average_prob(scores)\n",
    "\n",
    "    dd['sentiment_tweet'] = scores\n",
    "    dd['model_name'] = model_name\n",
    "    dd['data_name'] = dd_name\n",
    "    dd['subject'] = subj\n",
    "    \n",
    "    dd = dd[['id', 'model_name', 'data_name', 'subject', 'sentiment_tweet']]\n",
    "    \n",
    "    return(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b38dd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zero = [zero_model(x, y, d) for x in [*models] for y in subject_names for d in data_names]\n",
    "df_zero = pd.concat(df_zero)\n",
    "\n",
    "df_zero.to_csv(f'data/results/zero_shot_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5c3378",
   "metadata": {},
   "source": [
    "# Run Tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7557b3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_inputs(train_set, subj):\n",
    "\n",
    "    if train_set == 'handcode':\n",
    "        df = pd.read_csv('data/processed/handcode_tweets_processed.csv')\n",
    "    else:\n",
    "        df = datasets['pol'].copy()\n",
    "\n",
    "    if train_set == 'party':\n",
    "\n",
    "        # Get ID for train/test set, using same set as those used for GPT:\n",
    "        train_id = pd.read_csv(f\"data/training/training_key_{subj}.csv\")\n",
    "\n",
    "        id_train = train_id[train_id['train'] == True].id.values\n",
    "        id_test  = train_id[train_id['train'] == False].id.values\n",
    "        \n",
    "        # Set politician's sentiment to equal their aggrement with the candidate.\n",
    "        # based on party id. Only do this for \n",
    "        if subj == \"biden\":\n",
    "            df['party_bin'] = np.where(df['party_code'] == 'D', 1, 0)\n",
    "        elif subj == \"trump\":\n",
    "            df['party_bin'] = np.where(df['party_code'] == 'D', 0, 1)\n",
    "\n",
    "        # Create vectors for text and label\n",
    "        x_train, x_test = list(df[df['id'].isin(id_train)]['text']), list(df[df['id'].isin(id_test)]['text'])\n",
    "        y_train, y_test = list(df[df['id'].isin(id_train)]['party_bin']), list(df[df['id'].isin(id_test)]['party_bin'])\n",
    "\n",
    "    if train_set == 'nominate':\n",
    "\n",
    "        # Get ID for train/test set, using same set as those used for GPT:\n",
    "        train_id = pd.read_csv(f\"data/training/training_key_{subj}.csv\")\n",
    "\n",
    "        id_train = train_id[train_id['train'] == True].id.values\n",
    "        id_test  = train_id[train_id['train'] == False].id.values\n",
    "\n",
    "        # Reverse code nominate if subject is Biden\n",
    "        # since democrats are negative on scale. \n",
    "        if subj == 'biden':\n",
    "            df['nominate_dim1'] = np.where(df['nominate_dim1'] > 0, 0, 1)\n",
    "        elif subj == \"trump\":\n",
    "            df['nominate_dim1'] = np.where(df['nominate_dim1'] > 0, 1, 0)\n",
    "        \n",
    "        # Create vectors for text and label\n",
    "        x_train, x_test = list(df[df['id'].isin(id_train)]['text']), list(df[df['id'].isin(id_test)]['text'])\n",
    "        y_train, y_test = list(df[df['id'].isin(id_train)]['nominate_dim1']), list(df[df['id'].isin(id_test)]['nominate_dim1'])\n",
    "\n",
    "    if train_set == 'handcode':\n",
    "\n",
    "        # Get ID for train/test set, using same set as those used for GPT:\n",
    "        train_id = pd.read_csv(f\"data/training/training_key_{subj}_handcode.csv\")\n",
    "\n",
    "        id_train = train_id[train_id['train'] == True].id.values\n",
    "        id_test  = train_id[train_id['train'] == False].id.values\n",
    "    \n",
    "        # Set sentiment to positive/negative based off continuous score\n",
    "        df['score'] = np.where(df.score >= 0, 1, 0)\n",
    "        \n",
    "        # Create vectors for text and label\n",
    "        x_train, x_test = list(df[df['id'].isin(id_train)]['text']), list(df[df['id'].isin(id_test)]['text'])\n",
    "        y_train, y_test = list(df[df['id'].isin(id_train)]['score']), list(df[df['id'].isin(id_test)]['score'])\n",
    "\n",
    "    return [x_train, x_test, y_train, y_test]\n",
    "\n",
    "class torch_dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels is not None and len(self.labels) > 0:\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "    \n",
    "def compute_metrics(p):\n",
    "\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, pred, average = 'macro')\n",
    "\n",
    "    return {\"accuracy\": accuracy,\n",
    "           \"recall\": recall,\n",
    "           \"f1\": f1}\n",
    "\n",
    "def tune_model (model_name, train_set, subj):\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    mod = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = prep_inputs(train_set, subj)\n",
    "\n",
    "    # For tweetnlp, we need to relabel 1 to 2 since roberta uses label '1' as neutral\n",
    "    if model_name == 'cardiffnlp/twitter-roberta-base-sentiment-latest':\n",
    "        y_train = y_train * np.array(2)\n",
    "        y_test  = y_test * np.array(2)\n",
    "\n",
    "    # Deberta works a bit differently; it tests if a piece of text entails\n",
    "    # a given hypothesis. So, we need to append a hypothesis onto the\n",
    "    # tweet and interpret the results as the hypothesis being \"entailed\" or not.\n",
    "\n",
    "    # If we were following best practices, we would introduce variation into\n",
    "    # the hypothesis.\n",
    "    if model_name == 'MoritzLaurer/deberta-v3-large-zeroshot-v2.0':\n",
    "        hypothesis = f\"The stance of this text concerning {subj} is positive.\"\n",
    "\n",
    "        x_train_tokenized = tokenizer(x_train, [hypothesis]*len(x_train), padding = True, truncation = True, max_length = 512)\n",
    "        x_test_tokenized = tokenizer(x_test, [hypothesis]*len(x_test), padding = True, truncation = True, max_length = 512)\n",
    "    else:\n",
    "        # Use pretrained model to tokenize train/test text\n",
    "        x_train_tokenized = tokenizer(x_train, padding = True, truncation = True, max_length = 512)\n",
    "        x_test_tokenized = tokenizer(x_test, padding = True, truncation = True, max_length = 512)\n",
    "        \n",
    "    # Set up model arguments and training model\n",
    "    train_dataset = torch_dataset(x_train_tokenized, y_train)\n",
    "    test_dataset = torch_dataset(x_test_tokenized, y_test)\n",
    "    \n",
    "    # Siebert is too large for our GPU so we need to add gradient checkpointing\n",
    "    if model_name == \"siebert/sentiment-roberta-large-english\":\n",
    "        args = TrainingArguments(\n",
    "\n",
    "            output_dir = \"output\",\n",
    "            eval_strategy = \"epoch\",\n",
    "\n",
    "            per_device_train_batch_size = 32,\n",
    "            per_device_eval_batch_size = 32,\n",
    "            gradient_accumulation_steps = 4, \n",
    "            fp16 = True,\n",
    "\n",
    "            num_train_epochs = 2,\n",
    "            seed = 770,\n",
    "            load_best_model_at_end = True,\n",
    "            save_strategy = 'epoch',\n",
    "\n",
    "            metric_for_best_model='f1'\n",
    "\n",
    "        )\n",
    "    elif model_name == 'MoritzLaurer/deberta-v3-large-zeroshot-v2.0':\n",
    "\n",
    "        # Adapting arguments from Laurer's work:\n",
    "        # https://github.com/MoritzLaurer/zeroshot-classifier/blob/main/v2_synthetic_data/synth_train_eval.ipynb\n",
    "        args = TrainingArguments(\n",
    "\n",
    "            output_dir = \"output\",\n",
    "            eval_strategy = \"epoch\",\n",
    "\n",
    "            per_device_train_batch_size = 8,\n",
    "            per_device_eval_batch_size = 16,\n",
    "            fp16 = True,\n",
    "\n",
    "            warmup_ratio = 0.06,\n",
    "            weight_decay=0.01,\n",
    "            lr_scheduler_type= \"linear\",\n",
    "            learning_rate = 9e-6,\n",
    "            gradient_accumulation_steps = 8,\n",
    "            \n",
    "            num_train_epochs = 2,\n",
    "            seed = 770,\n",
    "            load_best_model_at_end = True,\n",
    "            save_strategy = 'epoch',\n",
    "\n",
    "            metric_for_best_model='f1'\n",
    "\n",
    "        )\n",
    "    else:\n",
    "        args = TrainingArguments(\n",
    "\n",
    "            output_dir = \"output\",\n",
    "            eval_strategy = \"epoch\",\n",
    "\n",
    "            per_device_train_batch_size = 32,\n",
    "            per_device_eval_batch_size = 32,\n",
    "            fp16 = True,\n",
    "\n",
    "            num_train_epochs = 2,\n",
    "            seed = 770,\n",
    "            load_best_model_at_end = True,\n",
    "            save_strategy = 'epoch',\n",
    "\n",
    "            metric_for_best_model='f1'\n",
    "\n",
    "        )\n",
    "        \n",
    "    trainer = Trainer(\n",
    "\n",
    "        model = mod,\n",
    "        args = args,\n",
    "        train_dataset = train_dataset,\n",
    "        eval_dataset = test_dataset,\n",
    "        compute_metrics = compute_metrics,\n",
    "        callbacks = [EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "\n",
    "        metric_for_best_model='f1'\n",
    "\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.evaluate()\n",
    "        \n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fc0084f-daca-45c0-bb23-43325c3d24b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_preds(df_name, mod, model_name, short_name, train_set, subj):\n",
    "\n",
    "    df = datasets[df_name]\n",
    "    df = df[df['subject'] == subj]\n",
    "    \n",
    "    tokenizer = tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    x = list(df['text'])\n",
    "\n",
    "    # Add on hypothesis for deberta, same as training version:\n",
    "    if (short_name == \"deberta\"):\n",
    "        hypothesis = f\"The stance of this text concerning {subj} is positive.\"\n",
    "        x = tokenizer(x, [hypothesis]*len(x), padding = True, truncation = True, max_length = 512)\n",
    "    else:\n",
    "        x = tokenizer(x, padding = True, truncation = True, max_length = 512)\n",
    "        \n",
    "    x = torch_dataset(x)\n",
    "    \n",
    "    preds = mod.predict(x)\n",
    "    preds = softmax(preds.predictions, axis = 1)\n",
    "    preds = average_prob(preds)\n",
    "    \n",
    "    df_pred = df[['id']]\n",
    "    df_pred['sentiment_tweet'] = preds\n",
    "            \n",
    "    save_file = f'data/results/{short_name}_tune_{train_set}_{df_name}_{subj}.csv'\n",
    "    \n",
    "    if os.path.exists(save_file):\n",
    "        os.remove(save_file)\n",
    "    \n",
    "    df_pred.to_csv(save_file, index = False)\n",
    "    \n",
    "    return f\"Saved {short_name} {train_set} {df_name} {subj}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3475013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_runs (model_name, short_name, train_set, subj):\n",
    "    \n",
    "    print(f\"Starting {short_name} {train_set} {subj}\")\n",
    "    \n",
    "    mod = tune_model(model_name, train_set, subj)\n",
    "\n",
    "    print(f\"Saving {short_name} {train_set} {subj}\")\n",
    "\n",
    "    model_path = f\"models/{short_name}_{train_set}_{subj}.pt\"\n",
    "    \n",
    "    #if os.path.exists(model_path):\n",
    "    #    os.remove(model_path)\n",
    "        \n",
    "    #torch.save(mod.model.state_dict(), model_path)\n",
    "\n",
    "    # Generate estimates from the model:\n",
    "    estimate_scores = [estimate_preds(df_name, mod, model_name, short_name, train_set, subj) for df_name in data_names]\n",
    "    \n",
    "    # Remove saved checkpoints\n",
    "    shutil.rmtree(\"output/\")\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    release_memory(mod)\n",
    "\n",
    "    return f\"Finished {short_name} {train_set} {subj}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005484be-fc2f-42cb-be04-6fc5067f84f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = [model_runs(model_name, short_name, train_set, subj) for short_name, model_name in models.items() for train_set in train_sets for subj in subject_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88b913c5-4d76-4e4d-aa4a-46025bbc611d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting deberta handcode trump\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 02:31, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.757743</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.152542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.332768</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.195238</td>\n",
       "      <td>0.136893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving deberta handcode trump\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting deberta handcode biden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:28, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.816646</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.398194</td>\n",
       "      <td>0.274725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.346559</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving deberta handcode biden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting deberta handcode trump\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:48, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.757743</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.152542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.332632</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.195238</td>\n",
       "      <td>0.136893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving deberta handcode trump\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting deberta handcode biden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:32, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.816646</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.398194</td>\n",
       "      <td>0.274725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.346559</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving deberta handcode biden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting deberta handcode trump\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 01:34, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.757743</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.152542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.332904</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.195238</td>\n",
       "      <td>0.136893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving deberta handcode trump\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting deberta handcode biden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:30, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.816646</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.398194</td>\n",
       "      <td>0.274725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.346559</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving deberta handcode biden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75783/266078096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['sentiment_tweet'] = preds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Finished deberta handcode trump',\n",
       " 'Finished deberta handcode biden',\n",
       " 'Finished deberta handcode trump',\n",
       " 'Finished deberta handcode biden',\n",
       " 'Finished deberta handcode trump',\n",
       " 'Finished deberta handcode biden']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache() \n",
    "[model_runs('MoritzLaurer/deberta-v3-large-zeroshot-v2.0', 'deberta', 'handcode', subj) for train_set in train_sets for subj in subject_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68ace582-9763-4f3c-97ec-3c9131a2758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets['kawintiranon']\n",
    "df = df[df['subject'] == 'biden']\n",
    "\n",
    "preds = pd.read_csv(\"data/results/deberta_tune_handcode_kawintiranon_biden.csv\")\n",
    "\n",
    "df = df.merge(preds, on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1198af75-fcec-4e15-b6fd-5294c2863034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joe Biden is looking to gather votes from unsu...</td>\n",
       "      <td>biden</td>\n",
       "      <td>1</td>\n",
       "      <td>6363</td>\n",
       "      <td>0.999823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Check out the latest podcast conversation betw...</td>\n",
       "      <td>biden</td>\n",
       "      <td>1</td>\n",
       "      <td>6364</td>\n",
       "      <td>-0.088407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you Secretary Clinton for your endorseme...</td>\n",
       "      <td>biden</td>\n",
       "      <td>1</td>\n",
       "      <td>6365</td>\n",
       "      <td>-0.583320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Happening now: @JoeBiden kicking off #Hispanic...</td>\n",
       "      <td>biden</td>\n",
       "      <td>1</td>\n",
       "      <td>6366</td>\n",
       "      <td>-0.886172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thank you Mayor @KeishaBottoms for opening our...</td>\n",
       "      <td>biden</td>\n",
       "      <td>1</td>\n",
       "      <td>6367</td>\n",
       "      <td>-0.978900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5801</th>\n",
       "      <td>Call me stubborn but I just dont think I wanna...</td>\n",
       "      <td>biden</td>\n",
       "      <td>1</td>\n",
       "      <td>12164</td>\n",
       "      <td>0.999807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5802</th>\n",
       "      <td>Crazy liberals lol progressive policies work b...</td>\n",
       "      <td>biden</td>\n",
       "      <td>1</td>\n",
       "      <td>12165</td>\n",
       "      <td>0.999850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5803</th>\n",
       "      <td>Lots of students @UWMadison awaiting @JoeBiden...</td>\n",
       "      <td>biden</td>\n",
       "      <td>1</td>\n",
       "      <td>12166</td>\n",
       "      <td>0.355268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5804</th>\n",
       "      <td>Other than the terrible grammar, is #Biden jus...</td>\n",
       "      <td>biden</td>\n",
       "      <td>1</td>\n",
       "      <td>12167</td>\n",
       "      <td>0.999881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5805</th>\n",
       "      <td>#Biden2020. Why dont the President and his sta...</td>\n",
       "      <td>biden</td>\n",
       "      <td>1</td>\n",
       "      <td>12168</td>\n",
       "      <td>0.999849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5806 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text subject  score     id  \\\n",
       "0     Joe Biden is looking to gather votes from unsu...   biden      1   6363   \n",
       "1     Check out the latest podcast conversation betw...   biden      1   6364   \n",
       "2     Thank you Secretary Clinton for your endorseme...   biden      1   6365   \n",
       "3     Happening now: @JoeBiden kicking off #Hispanic...   biden      1   6366   \n",
       "4     Thank you Mayor @KeishaBottoms for opening our...   biden      1   6367   \n",
       "...                                                 ...     ...    ...    ...   \n",
       "5801  Call me stubborn but I just dont think I wanna...   biden      1  12164   \n",
       "5802  Crazy liberals lol progressive policies work b...   biden      1  12165   \n",
       "5803  Lots of students @UWMadison awaiting @JoeBiden...   biden      1  12166   \n",
       "5804  Other than the terrible grammar, is #Biden jus...   biden      1  12167   \n",
       "5805  #Biden2020. Why dont the President and his sta...   biden      1  12168   \n",
       "\n",
       "      sentiment_tweet  \n",
       "0            0.999823  \n",
       "1           -0.088407  \n",
       "2           -0.583320  \n",
       "3           -0.886172  \n",
       "4           -0.978900  \n",
       "...               ...  \n",
       "5801         0.999807  \n",
       "5802         0.999850  \n",
       "5803         0.355268  \n",
       "5804         0.999881  \n",
       "5805         0.999849  \n",
       "\n",
       "[5806 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~df['sentiment_tweet'].apply(pd.api.types.is_float_dtype)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8815fa37-47cc-4112-b54f-ea67cb85aa8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>subject</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>imma keep it real with y’all i don’t think the...</td>\n",
       "      <td>0</td>\n",
       "      <td>biden</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER guess the #cult45 #trumpdrunkmorons can ...</td>\n",
       "      <td>0</td>\n",
       "      <td>biden</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>joe “let’s be reasonable guys not everybody ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>biden</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pelosi says biden shouldn't debate trump: 'i w...</td>\n",
       "      <td>-1</td>\n",
       "      <td>biden</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER hey @USER, here’s what your own party th...</td>\n",
       "      <td>0</td>\n",
       "      <td>biden</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>the publishing of a video by @USER that appear...</td>\n",
       "      <td>0</td>\n",
       "      <td>trump</td>\n",
       "      <td>2496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>@USER @USER what a fall from being a well like...</td>\n",
       "      <td>-1</td>\n",
       "      <td>trump</td>\n",
       "      <td>2497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>@USER nothing the #gop does surprises me anymo...</td>\n",
       "      <td>-1</td>\n",
       "      <td>trump</td>\n",
       "      <td>2498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>@USER if they are saying biden is doing it tha...</td>\n",
       "      <td>-1</td>\n",
       "      <td>trump</td>\n",
       "      <td>2499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>@USER before serving as florida’s worst ever a...</td>\n",
       "      <td>-1</td>\n",
       "      <td>trump</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  score subject    id\n",
       "0     imma keep it real with y’all i don’t think the...      0   biden     1\n",
       "1     @USER guess the #cult45 #trumpdrunkmorons can ...      0   biden     2\n",
       "2     joe “let’s be reasonable guys not everybody ca...      0   biden     3\n",
       "3     pelosi says biden shouldn't debate trump: 'i w...     -1   biden     4\n",
       "4     @USER hey @USER, here’s what your own party th...      0   biden     5\n",
       "...                                                 ...    ...     ...   ...\n",
       "2495  the publishing of a video by @USER that appear...      0   trump  2496\n",
       "2496  @USER @USER what a fall from being a well like...     -1   trump  2497\n",
       "2497  @USER nothing the #gop does surprises me anymo...     -1   trump  2498\n",
       "2498  @USER if they are saying biden is doing it tha...     -1   trump  2499\n",
       "2499  @USER before serving as florida’s worst ever a...     -1   trump  2500\n",
       "\n",
       "[2500 rows x 4 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = datasets['kawintiranon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcfc3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe indicating rows used for training v. eval.\n",
    "# We'll use this same set across all tuneable models.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, shuffle = True, random_state = 3812)\n",
    "df['train'] = df.text.isin(x_train)\n",
    "\n",
    "train_key = df[['id', 'train']]\n",
    "train_key['subject_name'] = pers\n",
    "\n",
    "train_key.to_csv(f'training_key_{pers}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "import os\n",
    "\n",
    "def get_gpu_memory():\n",
    "    command = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "    memory_free_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "    return memory_free_values\n",
    "\n",
    "get_gpu_memory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
